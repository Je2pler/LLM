exam;question_number;sub_question;question_type;extra_material;question;answer
4;1;"a";"Multiple choice";"NULL";"Select whether the following statement apply to 1. Frequentist, 2. Bayesian viewpoint or 3. both. Can be used to quantify the uncertainty of an estimate.";"Both. Given an estimate, frequentist can quantify the uncertanty using confidence intervals. Bayesian estimate the full probability of an estimate."
4;1;"b";"Multiple choice";"NULL";"Select whether the following statement apply to 1. Frequentist, 2. Bayesian viewpoint or 3. both. Parameters underlying an experiment are fixed values (deterministic).";"Frequentist."
4;1;"c";"Multiple choice";"NULL";"Select whether the following statement apply to 1. Frequentist, 2. Bayesian viewpoint or 3. both. Probabilities are beliefs. Starting with a prior belief the probability can be updated with experimental observations.";"Bayesian"
4;1;"d";"Multiple choice";"NULL";"Select whether the following statement apply to 1. Frequentist, 2. Bayesian viewpoint or 3. both. Parameters underlying an experiment are random variables.";"Bayesian."
4;1;"e";"Multiple choice";"NULL";"Consider: $y=0.1x_1+0.2x_2+0.3+\epsilon$, where: $\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} \sim  \mathcal{N}\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0.8 & 0.2 \\ 0.2 & 0.8 \end{bmatrix}\right)$ and $\epsilon \sim \mathcal{N}(0,0.2)$ is sampled independently from $x_1, x_2$. What is the probability distribution of y: 1. Poisson, 2. None of the above, 3. Weibull, 4. Bernoulli, 5. Gaussian. Select one alternative.";"Gaussian. y has a Gaussian distribution, since it is obtained by the affine transformation of Gaussians (Corollary 2)."
4;1;"f";"Multiple choice";"NULL";"Consider: $y=0.1x_1+0.2x_2+0.3+\epsilon$, where: $\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} \sim  \mathcal{N}\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0.8 & 0.2 \\ 0.2 & 0.8 \end{bmatrix}\right)$ and $\epsilon \sim \mathcal{N}(0,0.2)$ is sampled independently from $x_1, x_2$. What is the mean of y? (1) 0.1, (2) 0.3, (3) 0.2, (4) 0.4, (5) 0.8. Select one alternative.";"(2) 0.3 since $E[y] = E[0.1x_1 + 0.2x_2 + 0.3 + \epsilon] = 0.1E[x_1] + 0.2E[x_2] + 0.3 + E[\epsilon] = 0.1\cdot 0 + 0.2\cdot 0 + 0.3 + 0 = 0.3$"
4;1;"g";"Multiple choice";"NULL";"Consider: $y=0.1x_1+0.2x_2+0.3+\epsilon$, where: $\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} \sim  \mathcal{N}\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0.8 & 0.2 \\ 0.2 & 0.8 \end{bmatrix}\right)$ and $\epsilon \sim \mathcal{N}(0,0.2)$ is sampled independently from $x_1, x_2$. What is the variance of y? (1) 0.248, (2) 0.3, (3) 0.2, (4) 0.344, (5) 0.4. Select one alternative.";"0.248 since $\text{Var}[y] = \begin{bmatrix} 0.1 & 0.2 & 1 \end{bmatrix}\begin{bmatrix} 0.8 & 0.2 & 0 \\ 0.2 & 0.8 & 0 \\ 0 & 0 & 0.2 \end{bmatrix}  \begin{bmatrix} 0.1 \\ 0.2 \\ 1 \end{bmatrix} = 0.248$"
4;1;"h";"Multiple choice";"NULL";"Consider: $y=0.1x_1+0.2x_2+0.3+\epsilon$, where: $\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} \sim  \mathcal\{N\}\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0.8 & 0.2 \\ 0.2 & 0.8 \end{bmatrix}\right)$ and $\epsilon \sim \mathcal{N}(0,0.2)$ is sampled independently from $x_1, x_2$. If instead we choose $\epsilon$ an uniformly distributed random variable with the same mean and the same variance. 1. y will have the same distribution, but different mean and variance. 2. Nothing will change. 3. y will have a different distribution, but the same mean and variance. 4. y will have a different distribution and variance, but the same mean. 5. y will have a different distribution, variance and mean. Select one alternative.";"y will have a different distribution, but the same mean and variance."
4;2;"a";"Essay";"BNupg2.png";"Consider the Bayesian network in the image provided. The graphical representation indicates that a joint distribution can be fatorized p(A,B,C,D,E,F,G) into a product of terms. What is the factorization encoded in the Bayesian network?";"$p(A, B, C, D, E, F ) = p(A)p(B)p(C)p(D)p(E|A, B)p(F |C, D)p(G|E, F )$"
4;2;"b";"Multiple choice";"BNupg2.png";"Consider the Bayesian network in the image provided. True or false:  $A \perp\!\!\!\perp B$ (text: A is independent of B)";"True: the path between A and B is blocked. The path A-E-B does not have observed descendants neither is D observed hence it is blocked."
4;2;"c";"Multiple choice";"BNupg2.png";"Consider the Bayesian network in the image provided. True or false:  $A \perp\!\!\!\perp G$ (text: A is independent of G)";"False: there is a non-blocked path A-E-G."
4;2;"d";"Multiple choice";"BNupg2.png";"Consider the Bayesian network in the image provided. True or false: $A \perp\!\!\!\perp B|D$ (text: A is independent of B given D)";"True: the path between A and B is blocked. The path A-E-B does not have observed descendants neither is D observed hence it is blocked."
4;2;"e";"Multiple choice";"BNupg2.png";"Consider the Bayesian network in the image provided. True or false: $A \perp\!\!\!\perp B|E$ (text: A is independent of B given E)";"False: the path A-E-B is unblocked since E is observed."
4;2;"f";"Multiple choice";"BNupg2.png";"Consider the Bayesian network in the image provided. True or false: $A \perp\!\!\!\perp B|G$ (text: A is independent of B given G)";"False: the path A-E-B is unblocked since G, which is a descendent of E, is observed."
4;2;"g";"Multiple choice";"BNupg2.png";"Consider the Bayesian network in the image provided. True or false: $A \perp\!\!\!\perp G|E$ (text: A is independent of G given E)";"True: the path A-E-G is blocked since E is observed."
4;2;"h";"Multiple choice";"BNupg2.png";"Consider the Bayesian network in the image provided. True or false: $A \perp\!\!\!\perp C|G$ (text: A is independent of C given G)";"False: the path A-E-G-F-C is unblocked, since G is observed."
4;3;"a";"Multiple choice";"NULL";"Consider a simple binary classification problem. We are interested in the probability that a trained classifier will make a mistake,  $P(error)$. For each pair of answers below, choose whether 1. p(error)<=0.5, 2. p(error)>=0.5, 3. Cannot say based on the information provided. Question: The data used to train the classifier is linearly separable";"1. p(error)<=0.5 The classifier can trivially perform perfect classification."
