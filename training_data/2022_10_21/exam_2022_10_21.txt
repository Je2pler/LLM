exam, question_number, sub_question, question_type, extra_material, question, answer
KLAR 4, 1, "a", "Multible choice", NULL, "Select whether the following statement apply to 1. Frequentist, 2. Bayesian viewpoint or 3. both. Can be used to quantify the uncertainty of an estimate.", "Both. Given an estimate, frequentist can quantify the uncertanty using confidence intervals. Bayesian estimate the full probability of an estimate."
KLAR 4, 1, "b", "Multible choice", NULL, "Select whether the following statement apply to 1. Frequentist, 2. Bayesian viewpoint or 3. both. Parameters underlying an experiment are fixed values (deterministic).", "Frequentist."
KLAR 4, 1, "c", "Multible choice", NULL, "Select whether the following statement apply to 1. Frequentist, 2. Bayesian viewpoint or 3. both. Probabilities are beliefs. Starting with a prior belief the probability can be updated with experimental observations.", "Bayesian"
KLAR 4, 1, "d", "Multible choice", NULL, "Select whether the following statement apply to 1. Frequentist, 2. Bayesian viewpoint or 3. both. Parameters underlying an experiment are random variables.", "Bayesian."
KLAR 4, 1, "e", "Multible choice", NULL, "Consider: $y=0.1x_1+0.2x_2+0.3+\epsilon$, where: $\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} \sim  \mathcal{N}\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0.8 & 0.2 \\ 0.2 & 0.8 \end{bmatrix}\right)$ and $\epsilon \sim \mathcal{N}(0,0.2)$ is sampled independently from $x_1, x_2$. What is the probability distribution of y: 1. Poisson, 2. None of the above, 3. Weibull, 4. Bernoulli, 5. Gaussian. Select one alternative.", "Gaussian. y has a Gaussian distribution, since it is obtained by the affine transformation of Gaussians (Corollary 2)."
UTVECKLA SVAR 4, 1, "f", "Multible choice", NULL, "Consider: $y=0.1x_1+0.2x_2+0.3+\epsilon$, where: $\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} \sim  \mathcal{N}\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0.8 & 0.2 \\ 0.2 & 0.8 \end{bmatrix}\right)$ and $\epsilon \sim \mathcal{N}(0,0.2)$ is sampled independently from $x_1, x_2$. What is the mean of y? (1) 0.1, (2) 0.3, (3) 0.2, (4) 0.4, (5) 0.8. Select one alternative.", "0.3"
UTVECKLA SVAR 4, 1, "g", "Multible choice", NULL, "Consider: $y=0.1x_1+0.2x_2+0.3+\epsilon$, where: $\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} \sim  \mathcal{N}\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0.8 & 0.2 \\ 0.2 & 0.8 \end{bmatrix}\right)$ and $\epsilon \sim \mathcal{N}(0,0.2)$ is sampled independently from $x_1, x_2$. What is the variance of y? (1) 0.248, (2) 0.3, (3) 0.2, (4) 0.344, (5) 0.4. Select one alternative.", "0.248"
KLAR 4, 1, "h", "Multible choice", NULL, "Consider: $y=0.1x_1+0.2x_2+0.3+\epsilon$, where: $\begin{bmatrix} x_1 \\ x_2 \end{bmatrix} \sim  \mathcal{N}\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0.8 & 0.2 \\ 0.2 & 0.8 \end{bmatrix}\right)$ and $\epsilon \sim \mathcal{N}(0,0.2)$ is sampled independently from $x_1, x_2$. If instead we choose $\epsilon$ an uniformly distributed random variable with the same mean and the same variance. 1. y will have the same distribution, but different mean and variance. 2. Nothing will change. 3. y will have a different distribution, but the same mean and variance. 4. y will have a different distribution and variance, but the same mean. 5. y will have a different distribution, variance and mean. Select one alternative.", " y will have a different distribution, but the same mean and variance."
KLAR 4, 3, "a", "Numeric entry", NULL, "Assume that you have two binary random variables X  and Y. And that you know their joint probability distribution: $p(X=0,Y=0)=0.3$, $p(X=0,Y=1)=0.1$, $p(X=1,Y=0)=0.2$, $p(X=1,Y=1)=0.4$. Compute the following expectation analytically: $E{X+Y}$.", "1.1"
KLAR 4, 3, "b", "Numeric entry", NULL, "Assume that you have two binary random variables X  and Y. And that you know their joint probability distribution: $p(X=0,Y=0)=0.3$, $p(X=0,Y=1)=0.1$, $p(X=1,Y=0)=0.2$, $p(X=1,Y=1)=0.4$. Compute the following expectation analytically: $E{XY^2}$.", "0.4"
KLAR 4, 3, "c", "Numeric entry", NULL, "Assume that you have two binary random variables X  and Y. And that you know their joint probability distribution: $p(X=0,Y=0)=0.3$, $p(X=0,Y=1)=0.1$, $p(X=1,Y=0)=0.2$, $p(X=1,Y=1)=0.4$. Compute the following expectation analytically: $E{cos(\pi X)}$.", "-0.2"
UTVECKLA SVAR 4, 3, "d", "Numeric entry", NULL, "Assume that you have two binary random variables X  and Y. And that you know their joint probability distribution: $p(X=0,Y=0)=0.3$, $p(X=0,Y=1)=0.1$, $p(X=1,Y=0)=0.2$, $p(X=1,Y=1)=0.4$. Compute the following conditional probabilities: $P(X=1|Y=0)$.", "0.4"
UTVECKLA SVAR 4, 3, "e", "Numeric entry", NULL, "Assume that you have two binary random variables X  and Y. And that you know their joint probability distribution: $p(X=0,Y=0)=0.3$, $p(X=0,Y=1)=0.1$, $p(X=1,Y=0)=0.2$, $p(X=1,Y=1)=0.4$. Compute the following conditional probabilities: $P(X=1|Y=1)$.", "0.8"
UTVECKLA SVAR 4, 3, "f", "Numeric entry", NULL, "Assume that you have two binary random variables X  and Y. And that you know their joint probability distribution: $p(X=0,Y=0)=0.3$, $p(X=0,Y=1)=0.1$, $p(X=1,Y=0)=0.2$, $p(X=1,Y=1)=0.4$. Compute the following conditional probabilities: $P(Y=1|X=0)$.", "0.25"
UTVECKLA SVAR 4, 3, "g", "Numeric entry", NULL, "Assume that you have two binary random variables X  and Y. And that you know their joint probability distribution: $p(X=0,Y=0)=0.3$, $p(X=0,Y=1)=0.1$, $p(X=1,Y=0)=0.2$, $p(X=1,Y=1)=0.4$. Compute the following conditional probabilities: $P(Y=1|X=1)$.", "0.667"
KLAR 4, 3, "h", "Programming", code.py, "Assume that you have two binary random variables X  and Y. And that you know their joint probability distribution: $p(X=0,Y=0)=0.3$, $p(X=0,Y=1)=0.1$, $p(X=1,Y=0)=0.2$, $p(X=1,Y=1)=0.4$. Implement a code to draw samples $(x_i, y_i),i=1,...L$ using a Gibbs sampler and approximate $E{XY}. Plot the trajectory of the estimation as a function of the number of samples, for L=1 to 10000 samples. What is burn-in period in a Gibbs sampler? Explain what you would need change in the code if you included a burn-in period.", answer.py
KLAR 4, 4, "a", "Multible choice", NULL, "Suppose that you are developing an optical instrument for the James Webb Space Telescope. The instrument will be used to study distant stars. Your task is to evaluate and compare different designs (e.g. different number of lenses and corresponding focal lengths). You conclude that it would probably be helpful to simulate what the resulting images would look like (without launching the instrument to space first!). You have access to a relatively large number of images, captured with a range of known designs, and would like to build a simulator that can synthesize new, realistic, images corresponding to a given design. The instrument has an image sensor of size 100 x 100 pixels. Independently of each other, each pixel corresponds to either a star, with probability $p$, or empty space, with probability $1-p$. Star pixels have different intensities distributed according to $I \sim \mathcal{N}(\mu_I,\sigma_I^2) while non-star pixels have zero intensity. Each pixel in the entire final image corresponds to the intensity plus some noise. The noise is Gaussian, with zero mean and variance $\sigma_d^2$ (known from the design). The noise in each pixel is independent and identically distributed. What type of machine learning approach describes this best? 1. Reinforcement learning, 2. Unsupervised learning, 3. Supervised learning, 4. Semi-supervised learning. Select one alternative.", "Since the goal is to generate data similar to a training data set, it is a form of unsupervised learning, more specifically generative modeling."
4, 4, "b", "Diagram", NULL, "Suppose that you are developing an optical instrument for the James Webb Space Telescope. The instrument will be used to study distant stars. Your task is to evaluate and compare different designs (e.g. different number of lenses and corresponding focal lengths). You conclude that it would probably be helpful to simulate what the resulting images would look like (without launching the instrument to space first!). You have access to a relatively large number of images, captured with a range of known designs, and would like to build a simulator that can synthesize new, realistic, images corresponding to a given design. The instrument has an image sensor of size 100 x 100 pixels. Independently of each other, each pixel corresponds to either a star, with probability $p$, or empty space, with probability $1-p$. Star pixels have different intensities distributed according to $I \sim \mathcal{N}(\mu_I,\sigma_I^2) while non-star pixels have zero intensity. Each pixel in the entire final image corresponds to the intensity plus some noise. The noise is Gaussian, with zero mean and variance $\sigma_d^2$ (known from the design). The noise in each pixel is independent and identically distributed. Draw a Bayesian network corresponding to the model."
FORTSÄTT HÄR:  4, 4, "c", "Numeric entry", NULL, 



Suppose that you are developing an optical instrument for the James Webb Space Telescope. The instrument will be used to study distant stars. Your task is to evaluate and compare different designs (e.g. different number of lenses and corresponding focal lengths). You conclude that it would probably be helpful to simulate what the resulting images would look like (without launching the instrument to space first!). You have access to a relatively large number of images, captured with a range of known designs, and would like to build a simulator that can synthesize new, realistic, images corresponding to a given design. The instrument has an image sensor of size 100 x 100 pixels. Independently of each other, each pixel corresponds to either a star, with probability $p$, or empty space, with probability $1-p$. Star pixels have different intensities distributed according to $I \sim \mathcal{N}(\mu_I,\sigma_I^2) while non-star pixels have zero intensity. Each pixel in the entire final image corresponds to the intensity plus some noise. The noise is Gaussian, with zero mean and variance $\sigma_d^2$ (known from the design). The noise in each pixel is independent and identically distributed.
SKRIV UPPGIFT 2