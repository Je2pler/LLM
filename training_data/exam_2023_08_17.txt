exam, question_number, question_type, question, answer

"""""" GÃ¶r klart senare""""""3, 1, "Essay", "What is the difference between Bayesian and frequentist machine learning models/methods? Give one example of each model/method category. Use maximum 150 words.", "Frequentistic machine learning assumes that there exists some true values underlying some experiment while Bayesian machine learning requires a prior belief of the distribution which is later fine tuned.
3, 1, "Essay", What is the difference between a supervised machine learning problem and an unsupervised machine learning problem? Use maximum 75 words., "In a supervised problem, we have access to multiple instances of input data $x_1, \dots, x_N$ and corresponding outputs $y_1, \dots, y_N$, which we denote as our training data. Our aim is to, based on this data, find a model $y = f(x)$ that relates the input and the output. In unsupervised learning, we don't have any outputs in our training data, we only have access to $x_1, \dots, x_N$. Here, we instead want to find meaningful patterns in the data."
3, 1, "Essay", "Consider the measurement model \[y_n = x + \epsilon_n, \quad n = 1, \dots, N\] where all noise terms $\epsilon_n \sim \mathcal{N}(0, 1^2)$ are independent. We now get $N = 2$ measurements $y_1 = 1$ and $y_2 = 2$. Together with the prior $x \sim \mathcal{N}(0, 2^2)$, what is the mean and standard deviation of the posterior?\[p(x \mid y_1, y_2) = \mathcal{N}(x; \mu_{x|y}, \sigma_{x|y}^2)\]", "Using corollary 1 we get \[\sigma^2_{x|y} = \left(     4^{-1} + \begin{bmatrix} 1 & 1 \end{bmatrix}    \begin{bmatrix}        1 & 0 \\        0 & 1     \end{bmatrix}    \begin{bmatrix} 1 \\ 1 \end{bmatrix}\right)^{-1} = \frac{4}{9}, \quad \Rightarrow \quad \sigma_{x|y} = \frac{2}{3}\]\[\mu_{x|y} = \frac{4}{9}\left( 0 + \begin{bmatrix} 1 & 1 \end{bmatrix}\begin{bmatrix}        1 & 0 \\        0 & 1     \end{bmatrix}    \left(         \begin{bmatrix} 1 \\ 2 \end{bmatrix} - \begin{bmatrix} 0 \\ 0 \end{bmatrix} \right)\right) = \frac{4}{3}\]"
3, 3, "Programming", "Consider the model \[ y_i = w_0 + w_1 x_i + w_2 x_i^2 + \epsilon_i \] where \[ \epsilon_i \sim \mathcal{N}(0, 1) \] and, the prior of the parameters is \[ w_j \sim \mathcal{N}(0, 1), \quad j = 0, 1, 2 \] Assume the following points are observed \[ \begin{array}{c|c} x & y \\ \hline 0.1 & 2.2 \\ 0.5 & 2.1 \\ 1 & 3.9 \\ 1.2 & 5.3 \\ 2 & 9.1 \\ 3 & 17.5 \end{array} \]. You will be asked to solve a Bayesian Linear Regression problem. The following code gives the structure for your implementation. -----------------ADD LINK TO CODE, The posterior distribution of the parameter vector $\mathbf{w} = [w_0, w_1, w_2]$ is normally distributed $ p(\mathbf{w} | D) \sim N(\mu,\Sigma)$.  For $D = (x_i,y_i), i = 1,2,3,4,5,6$ the datapoints in the table. Implement in python a routine to compute the values of $\mu$ and  $\Sigma$. Write the values in the box below with two decimal places. i) Write the value computed $\mu = \begin{bmatrix}    \mu_1\\ \mu_2 \\ \mu_3\end{bmatrix}$. \textbf{(2pts)}ii) Write the value computed for$\Sigma = \begin{bmatrix}    \Sigma_{1, 1} & \Sigma_{1, 2} & \Sigma_{1, 3} \\        \Sigma_{2, 1} & \Sigma_{2, 2} & \Sigma_{2, 3} \\            \Sigma_{3, 1} & \Sigma_{3, 2} & \Sigma_{3, 3} \\ \end{bmatrix}$ \textbf{(2pts)}", "NO CODE AVAILABLE IN SOLUTIONS"
3, 3, "Programming", "Given a set of 100 test points uniformly spaced between 0 and 4. For each one of these test points $x_*$ the posterior distribution $x_*|D$ is normal. Plot \begin{itemize} \item a line indicating the mean. \item one and two standard deviations from the mean. \item the training datapoints in the table.", 
3, 4, "Essay", "Consider two binary random variables $A, B \in \{0, 1}$ where the following numbers describe its joint distribution. $\begin{aligned} p(A=0,B=0)&=0\\p(A=0,B=1)&=0.5\\p(A=1,B=0)&=0.2\\p(A=1,B=1)&=0.3$. Compute the marginal distributions $p(A)$ and $p(B)$ as well as the conditional distributions $p(A|B)$ and $p(B|A)$." $p(A = 1) = p(A = 1, B = 0) + p(A = 1, B = 1) = 0.5\\p(B = 1) = p(A = 0, B = 1) + p(A = 1, B = 1) = 0.5 + 0.3 = 0.8\\p(A = 1|B = 0) = p(A = 1, B = 0)/p(B = 0) = 0.2/0.2 = 1.0\\p(A = 1|B = 1) = p(A = 1, B = 1)/p(B = 1) = 0.3/0.8 = 0.375\\p(B = 1|A = 0) = p(A = 0, B = 1)/p(A = 0) = 0.5/0.5 = 1.0\\p(B = 1|A = 1) = p(A = 1, B = 1)/p(A = 1) = 0.3/0.5 = 0.6$