exam;question_number;sub_question_number;question_type;extra_material;question;answer
3;1;"a";"Essay";"Null";"What is the difference between Bayesian and frequentist machine learning models/methods? Give one example of each model/method category. Use maximum 150 words.";"Bayesian and frequentist machine learning models differ mainly in how they interpret and handle uncertainty.Bayesian models incorporate prior beliefs, updating them with data to form a posterior distribution. They treat model parameters as random variables and use probability to quantify uncertainty. For example, Naive Bayes is a Bayesian method that assumes feature independence and uses Bayes' theorem to predict outcomes. Frequentist models interpret probability as the long-run frequency of events and treat model parameters as fixed but unknown. They rely on data alone without incorporating prior beliefs. For example, Linear Regression is a frequentist method that estimates model parameters by minimizing the difference between predicted and observed values (e.g., through least squares), without assuming a prior distribution for the parameters."
3;1;"b";"Essay";"Null";"What is the difference between a supervised machine learning problem and an unsupervised machine learning problem? Use maximum 75 words.";"In a supervised problem, we have access to multiple instances of input data $x_1, \dots, x_N$ and corresponding outputs $y_1, \dots, y_N$, which we denote as our training data. Our aim is to, based on this data, find a model $y = f(x)$ that relates the input and the output. In unsupervised learning, we don't have any outputs in our training data, we only have access to $x_1, \dots, x_N$. Here, we instead want to find meaningful patterns in the data."
3;1;"c";"Essay";"Null";"Consider the measurement model \[y_n = x + \epsilon_n, \quad n = 1, \dots, N\] where all noise terms $\epsilon_n \sim \mathcal{N}(0, 1^2)$ are independent. We now get $N = 2$ measurements $y_1 = 1$ and $y_2 = 2$. Together with the prior $x \sim \mathcal{N}(0, 2^2)$, what is the mean and standard deviation of the posterior?\[p(x \mid y_1, y_2) = \mathcal{N}(x: \mu_{x|y}, \sigma_{x|y}^2)\]";"Using corollary 1 we get \[\sigma^2_{x|y} = \left(     4^{-1} + \begin{bmatrix} 1 & 1 \end{bmatrix}    \begin{bmatrix}        1 & 0 \\        0 & 1     \end{bmatrix}    \begin{bmatrix} 1 \\ 1 \end{bmatrix}\right)^{-1} = \frac{4}{9}, \quad \Rightarrow \quad \sigma_{x|y} = \frac{2}{3}\]\[\mu_{x|y} = \frac{4}{9}\left( 0 + \begin{bmatrix} 1 & 1 \end{bmatrix}\begin{bmatrix}        1 & 0 \\        0 & 1     \end{bmatrix}    \left(         \begin{bmatrix} 1 \\ 2 \end{bmatrix} - \begin{bmatrix} 0 \\ 0 \end{bmatrix} \right)\right) = \frac{4}{3}\]"
3;2;"a";"Multiple Choice";"BN_q2.png";"In this problem we will consider the Bayesian network in the provided image. Consider the Bayesian network illustrated in the image provided. From the Bayesian network we can conclude that: (True or false)  $A \perp\!\!\!\perp B | C$ (text: A is independent of B given C).";"False, they are connected along the path A-B." 
3;2;"b";"Multiple Choice";"BN_q2.png";"In this problem we will consider the Bayesian network in the provided image. Consider the Bayesian network illustrated in the image provided. From the Bayesian network we can conclude that: (True or false)  $A \perp\!\!\!\perp C | B$ (text: S is independent of C given B).";"True, the path A-B-C blocked at node B (observed head-to-tail)."
3;2;"c";"Multiple Choice";"BN_q2.png";"In this problem we will consider the Bayesian network in the provided image. Consider the Bayesian network illustrated in the image provided. From the Bayesian network we can conclude that: (True or false)  $A \perp\!\!\!\perp C | B, D$ (text: A is independent of C given B and D).";"True, the path B-D-E blocked at node D"
3;2;"d";"Multiple Choice";"BN_q2.png";"In this problem we will consider the Bayesian network in the provided image. Consider the Bayesian network illustrated in the image provided. From the Bayesian network we can conclude that: (True or false)  $A \perp\!\!\!\perp C | B, E$ (text: A is independent of C given B and E).";"False, the path A-B-D-E is neither blocked at node B nor D"
3;2;"e";"Multiple Choice";"BN_q2.png";"In this problem we will consider the Bayesian network in the provided image. Consider the Bayesian network illustrated in the image provided. From the Bayesian network we can conclude that: (True or false)  $A \perp\!\!\!\perp E | C$ (text: A is independent of E given C).";"True, C-B-D-E is blocked at node B"
3;2;"f";"Multiple Choice";"BN_q2.png";"In this problem we will consider the Bayesian network in the provided image. Consider the Bayesian network illustrated in the image provided. From the Bayesian network we can conclude that: (True or false)  $A \perp\!\!\!\perp E (text: A is independent of E).";"False, C-B-D-E is neither blocked at node D nor at node B."
3;3;"a";"Programming";"code_template_2023_08_17.py";"Consider the model \[ y_i = w_0 + w_1 x_i + w_2 x_i^2 + \epsilon_i \] where \[ \epsilon_i \sim \mathcal{N}(0, 1) \] and, the prior of the parameters is \[ w_j \sim \mathcal{N}(0, 1), \quad j = 0, 1, 2 \] Assume the following points are observed \[ \begin{array}{c|c} x & y \\ \hline 0.1 & 2.2 \\ 0.5 & 2.1 \\ 1 & 3.9 \\ 1.2 & 5.3 \\ 2 & 9.1 \\ 3 & 17.5 \end{array} \]. You will be asked to solve a Bayesian Linear Regression problem. The provided code gives the structure for your implementation. The posterior distribution of the parameter vector $\mathbf{w} = [w_0, w_1, w_2]$ is normally distributed $ p(\mathbf{w} | D) \sim N(\mu,\Sigma)$.  For $D = (x_i,y_i), i = 1,2,3,4,5,6$ the datapoints in the table. Implement in python a routine to compute the values of $\mu$ and  $\Sigma$. Then, given a set of 100 test points uniformly spaced between 0 and 4. For each one of these test points $x_*$ the posterior distribution $x_*|D$ is normal. Implement in python a routine to plot \begin{itemize} \item a line indicating the mean. \item one and two standard deviations from the mean. \item the training datapoints in the table.";"code_2023_08_17.py"
3;4;"a";"Essay";"Null";"Consider two binary random variables $A, B \in \{0, 1}$ where the following numbers describe its joint distribution. $\begin{aligned} p(A=0,B=0)&=0\\p(A=0,B=1)&=0.5\\p(A=1,B=0)&=0.2\\p(A=1,B=1)&=0.3$. Compute the marginal distributions $p(A)$ and $p(B)$ as well as the conditional distributions $p(A|B)$ and $p(B|A)$.";"$p(A = 1) = p(A = 1, B = 0) + p(A = 1, B = 1) = 0.5\\p(B = 1) = p(A = 0, B = 1) + p(A = 1, B = 1) = 0.5 + 0.3 = 0.8\\p(A = 1|B = 0) = p(A = 1, B = 0)/p(B = 0) = 0.2/0.2 = 1.0\\p(A = 1|B = 1) = p(A = 1, B = 1)/p(B = 1) = 0.3/0.8 = 0.375\\p(B = 1|A = 0) = p(A = 0, B = 1)/p(A = 0) = 0.5/0.5 = 1.0\\p(B = 1|A = 1) = p(A = 1, B = 1)/p(A = 1) = 0.3/0.5 = 0.6$"